---
documentclass: jss
bibliography: article.bib
author:
  - name: FirstName LastName
    orcid: 0000-0000-0000-0000
    affiliation: University/Company
    # use this syntax to add text on several lines
    address: |
      | First line
      | Second line
    email: \email{name@company.com}
    url: https://posit.co
  - name: Second Author
    orcid: 0000-0000-0000-0000
    affiliation: 'Affiliation \AND'
    # To add another line, use \AND at the end of the previous one as above
  - name: Third Author
    orcid: 0000-0000-0000-0000
    affiliation: 'Affiliation'
    # To add another line, use \AND at the end of the previous one as above
  - name: Third Author
    orcid: 0000-0000-0000-0000
    affiliation: 'Affiliation \AND'
    # To add another line, use \AND at the end of the previous one as above
  - name: Third Author
    orcid: 0000-0000-0000-0000
    affiliation: 'Affiliation'
    # To add another line, use \AND at the end of the previous one as above
  - name: Fourth Author
    orcid: 0000-0000-0000-0000
    address: |
      | Department of Statistics and Mathematics,
      | Faculty of Biosciences,
      | Universitat Autònoma de Barcelona
    affiliation: |
      | Universitat Autònoma 
      | de Barcelona
    # use a different affiliation in adress field (differently formated here)
    affiliation2: Universitat Autònoma de Barcelona
title:
  formatted: "Reservoir computing in R : a tutorial using \\pkg{reservoirnet}"
  # If you use tex in the formatted title, also supply version without
  plain:     "Reservoir computing in R : a tutorial using reservoirnet"
  # For running headers, if needed
  short:     "\\pkg{reservoirnet}: reservoir computing in R"
abstract: >
  The abstract of the article.
keywords:
  # at least one keyword must be supplied
  formatted: [keywords, not capitalized, "\\proglang{Java}"]
  plain:     [keywords, not capitalized, Java]
preamble: >
  \usepackage{amsmath}
output:
  bookdown::pdf_book:
    base_format: rticles::jss_article
  bookdown::word_document2:
    default
knit: (function(inputFile, encoding){
  rmarkdown::render(inputFile, encoding = encoding,
  output_dir = here::here("draft_jss"), output_format = "all") })
---

```{r, setup, include=FALSE}
options(prompt = 'R> ', continue = '+ ')
set.seed(1)
```

# Introduction

## Reservoir networks presentation

Reservoir Computing (RC) is a prominent machine learning methodology
that has gained significant attention in recent years for its ability to
effectively process information generated by dynamical systems. This
innovative approach leverages the dynamics of a high-dimensional
reservoir to perform complex computations and solve various tasks based
on the response of this dynamical system to input signals. Reservoir
Computing is characterized by its unique architecture, which includes a
dynamic system, often referred to as a reservoir, that projects temporal
input signals onto a high-dimensional feature space. This
high-dimensional representation of input data enables Reservoir
Computing to excel in tasks such as time series prediction, pattern
recognition, and signal processing.

## Why reservoir are interesting compared to standard approaches (penalised regression) and deep learning approaches?

RC exhibits several advantages over its counterparts. It excels in tasks
that require the processing of temporal data, such as time series
forecasting and speech recognition, thanks to its inherent memory
capabilities. RC offers computational efficiency, reduced susceptibility
to overfitting, and a higher degree of interpretability compared to deep
learning models. Moreover, RC is able to capture intricate temporal
patterns compared to statistical methods such as penalized regression.

## examples of previous use

TODO: - Ghosh S, Senapati A, Mishra A, Chattopadhyay J, Dana SK, Hens C,
et al. Reservoir computing on epidemic spreading: A case study on
COVID-19 cases. Phys Rev E. 16 juill 2021;104(1):014308. - Existing
review?

## challenges of using reservoir

RC use is stille challenging for several reasons. First, its stochastic
nature due to the reservoir random part makes the results of a given RC
unpredictable even if the hyperparameters are well chosen. Second,
eventhough, RC relies on several hyperparameter to determine the
connections between neurons. There exist few guidance about the way to
set the hyperparameters and most often the user must rely on a wrapper
approach were combinations of hyperparameters performance are evaluated
on a train set before chosing the ideal combination one. Third, most
published paper are based on a low dimensional setting and few guidance
exist in the context of high dimensional data, especially considering
the choice of hyperparameters. Fourth, the use of reservoir computing in
an epidemic setting with highly non-stationary time serie is scarce
whereas it is of tremendous interest for epidemiologists. Fifth, there
is currently no implementation available on R making the use of this
method challenging for user not familiar with Python.

## what we do

In this paper we propose to explore those challenges with extensive
guidance in order to help new user to fully benefit from RC. First a
general introduction to reservoir computing is provided with a tutorial
for its use using reservoirnet, a R package based on reservoirPy Python
module. Second, we explore the different challenges of the use of RC in
a non-stationary high dimensional setting based on the use case of
covid-19 hospitalisations forecast with extensive guidance on the
modelling strategy, the choice of hyperparameters using a genetic
algorithm and the implementation.

# RC presentation

RC is a machine learning algorithm composed of an input layer denoted
$u(t)$ which is randomy transformed by the reservoir into an activation
state denoted $x(t)$ which is fed to a ridge penalized linear regression
trained to foreast the outcome denoted as $y(t)$ as depicted at figure
\@ref(fig:rcpresentation).

```{r rcpresentation, echo=FALSE, fig.cap="my caption", out.width = '90%', fig.cap="Reservoir computing is composed of an input layer, a reservoir and an output layer. Connection between input layer and reservoir and inside reservoir are random. Only the output layer is optimized based on a ridge penalized linear regression."}
knitr::include_graphics("images/schema.png/image1.png")
```

The input layer $u(t)$ is an $M$-dimension vector which corresponds to
the values of the input time series at time $t$ where $t = 1, …, T$. The
reservoir layer $x(t)$ is an $N_{res}$-dimensional vector where
$N_{res}$ is the number of nodes in the reservoir. The value $x(t)$ is
defined as follow:

$$x( t+1 ) = ( 1 - \alpha )  x ( t) + \alpha \: tanh( W x(t) + W_{in} u(t+1) )", "ext{ where } \alpha \in [0, 1 ]$$

The leaking rate alpha define the rate of update of the nodes. The
closer $\alpha$ is to $1$, the higher the reservoir is sensitive to new
inputs (i.e $u(t)$). Therefore, the reservoir state at time $t+1$
denoted $x(t+1)$ depends on the reservoir state at the previous time
(i.e $x(t)$) and the new inputs (i.e $u(t+1)$). Both $W_{in}$ and $W$
are random matrices of size $Nres", "imes M$ and $Nres", "imes Nres$
respectively.

$W_{in}$ is a dense matrix generated using a bernouilli distribution
where each value can be either $-I_{scale}(m)$ or $I_{scale}(m)$ with an
equal probability where $m = 1, …, M$ corresponds to a given feature in
the input layer. The input scaling, denoted $I_{scale}$, is an
hyperparameter coefficient which can be common to all features from the
input layer or specific to each feature $m$. In that case, the more
important the feature is, the greater should be its input scaling. $W$
is a sparse matrix where values are generated base on a gaussian
distribution $\mathcal{N}(0,1)$. Then the matrix $W$ is rescaled
according to the spectral radius, an hyperparameter defining the highest
eigen value of $W$.

The final layer is a linear regression with ridge penalization where the
explanatory features are the reservoir state and the variable to be
explain is the outcome to predict such that:

$$W_{out} = YX^T ( XX^T + \lambda  I)^{ -1 }$$

Where x(t) and y(t) are accumulated in X and Y respectively such that:

$$X = \begin{bmatrix} x(1) \\ x(2) \\ ... \\ x(T) \end{bmatrix}
\text{ and } Y = \begin{bmatrix} y(1) \\ y(2) \\ ... \\ y(T) \end{bmatrix}$$

The parameter $\lambda$ is the ridge penalisation which aims to prevent
overfitting.

Overall, there are four main hyperparameters to be chosen by the user:
the leaking rate wich defines the memory of the RC, the input scaling
wich define the relative importance of the features, the spectral radius
wich define the connections of the neurons inside the reservoir and the
ridge penalization wich defines the degree of overfitting. The choice of
hyperparameter is difficult and the use of a wrapper approach where the
performance of the RC with different combinations of hyperparameters is
evaluated on a train set, the best combination is chosen for the use on
the test set.

RC in high dimension

The interest of RC in high dimensional setting is unclear for at least
two reasons: (i) RC relies primarily on the projection of the low
dimension input layer to the high dimension space of the reservoir
neurons and (ii) the high number of features for which each can be
associated with a different input scaling increases the hyperparameter
search space making standard approaches such as random search or grid
search inefficient.

# Basic package use

In this section, we will cover the basics of reservoirnet use including
installation, classification and regression. We will provide brief
overview of the package use and more in depth description is provided in
section 4 with the covid-19 forecast use case.

## Installation

reservoirnet is an R package api making the python module reservoirPy
easily callable from R. It is available on CRAN (see
<https://cran.r-project.org/package=reservoirnet>) and can be installed
using:

```{r eval=FALSE}
install.packages("reservoirnet")
```

Reservoir Computing (RC) is well suited to both regression and
classification tasks. We will introduce a simple example for both task.

## Regression {#basicregression}

### Covid-19 data

In this first use case, we will introduce the fundamental usage of the `reservoirnet` package. This demonstration will be conducted using the COVID-19 dataset that is included within the package. These data encompass hospitalization figures, positive RT-PCR results, and overall RT-PCR data sourced from Santé Publique France, which are publicly available on data.gouv.fr (for further details, refer to the `help(dfCovid)` function). Our primary objective is to predict the number of hospitalized patients 14 days into the future. To accomplish this, we will initially train our model on data preceding the date of January 1, 2022, and subsequently apply it to forecast values using the subsequent dataset.

We can proceed by loading useful packages (i.e ggplot2 [@wickham_ggplot2_2016] and dplyr [@wickham_dplyr_2023]), data and define the task:

```{r message=FALSE, warning=FALSE}
library(dplyr)
library(ggplot2)
library(reservoirnet)

data("dfCovid")
dist_forecast = 14
traintest_date = as.Date("2022-01-01")
```

Due to the substantial fluctuations observed in both RT-PCR metrics, our initial step involves applying a moving average computation over the most recent 7-day periods for these features. Additionally, we augment the dataset by introducing an `outcome` column and an `outcomeDate` column, which will serve as valuable inputs for model training. Moreover, we calculate the `outcome_deriv` as the difference between the outcome and the number of hospitalized patients (`hosp`), representing the variation in hospitalization in relation to the current count of hospitalized individuals. The resulting smoothed data is visualized in Figure @ref(fig:covidintro).

```{r}
dfOutcome <- dfCovid %>%
  # outcome at 14 days
  mutate(outcome = lead(x = hosp, n = dist_forecast),
         outcomeDate = date + dist_forecast,
         outcome_deriv = outcome - hosp) %>%
  # rolling average for tested and positive_pcr
  mutate_at(.vars = c("Positive", "Tested"),
            .funs = function(x) slider::slide_dbl(.x = x,
                                                  .before = 6,
                                                  .f = mean))
```

We can now plot the data :

```{r covidintro, fig.cap="Hospitalisations, IPTCC and positive PCR of Bordeaux University Hospital.", echo = FALSE}
dfOutcome %>%
  tidyr::pivot_longer(cols = c("hosp", "Positive", "Tested")) %>%
  ggplot2::ggplot(mapping = aes(x = date, y = value)) +
  geom_line() +
  facet_grid(name ~ ., scales = "free_y") +
  theme_bw() +
  geom_vline(mapping = aes(color = "train-test sets",
                           xintercept = traintest_date)) +
  labs(color = "") +
  theme(legend.position = "bottom")
```

### First reservoir

Setting a reservoir is done with the `createNode()` function. The important hyperparameters are the following :

-   Number of nodes (`units`) : it corresponds to the number of nodes inside the reservoir. Usually, the more the better but more nodes increase the computation time.
-   Leaking rate (`lr`) : the leaking rate corresponds to the balance between the new inputs and the previous state. A leaking rate of 1 only consider informations from the new inputs.
-   Spectral radius (`sr`): the spectral radius is the maximum absolute eigenvalue of the reservoir connectivity matrix. A small spectral radius induces stable dynamics inside the reservoir, a high spectral radius induces chaotic regimen inside the reservoir.
-   Input scaling (`input_scaling`): the input scaling is a gain applied to the input features of the reservoir.
-   Seed (`seed`): because the reservoir connections are set at random, setting the seed is a good approach to ensure   reproducibility. Another approach would be to use several different reservoir but it increases computation time.

For this part of the tutorial, we will set the hyperparameter at a given value. Hyperparameter opitmisation will be detailed at section [Study case](#studycase).

```{r}
reservoir <- reservoirnet::createNode(nodeType = "Reservoir",
                                      seed = 1,
                                      units = 500,
                                      lr = 0.7,
                                      sr = 1,
                                      input_scaling = 1)
```

Then we can feed the data to the reservoir and see the activation depending on time of the reservoir. To do so, we first prepare the data and transform it to a matrix :

```{r}
## select explanatory and transform it to an array
X <- dfOutcome %>%
  filter(outcomeDate < traintest_date) %>%
  select(hosp, Positive, Tested) %>%
  as.matrix()
```

Then we run the `predict_seq` function. It takes as input a node (i.e a reservoir or a reservoir associated with an output layer) and the feature matrix.

```{r}
reservoir_state <- predict_seq(node = reservoir, X = X)
```

Now we can visualise node activation using the `plot` function presented at figure \@ref(fig:nodeactivationbad).

```{r nodeactivationbad, fig.cap="Node acivation over time."}
plot(reservoir_state)
```

Numerous nodes within the system exhibit a consistent equilibrium state. The challenge arises when the ridge output layer attempts to acquire knowledge from these nodes, as they do not convey meaningful information. This issue can be attributed to the disparate scales of the features. To address this concern, a practical approach involves normalizing the features by dividing each of them by their respective maximum values, thereby rescaling them within the range of `-1` to `1`.

```{r}
stand_max <- function(x) return(x/max(x))
# scaled features
Xstand <- dfOutcome %>%
  filter(date < traintest_date) %>%
  select(hosp, Positive, Tested) %>%
  mutate_all(.funs = stand_max) %>%
  as.matrix() %>%
  as.array()
```

We then feed them to the reservoir and plot the node activation again. Compared to \@ref(fig:nodeactivationbad), the obtained node activation \@ref(fig:nodeactivationgood) shows interesting trend outputs as no node seems saturated.

```{r nodeactivationgood, fig.cap="Node acivation over time. Scaled features"}
# feed them to the reservoir
reservoir_state_stand <- predict_seq(node = reservoir,
                                     X = Xstand,
                                     reset = TRUE)
# plot the output
plot(reservoir_state_stand)
```

### Forecast

In order to train the reservoir, we should train the last layer which
linearly combines the neuron's output.

#### Set the ESN

Initially, we establish the output layer, incorporating a ridge penalty set at `1e3`. It's important to note that this hyperparameter can be subject to optimization, a topic that will be explored in the forthcoming [Study Case](#studycase) section. This parameter plays a pivotal role in fine-tuning the model's conformity to the dataset. When set excessively high, the risk of underfitting arises, whereas setting it too low can lead to overfitting. Then we connect the output layer to the reservoir making the model ready to be trained.

```{r}
readout <- reservoirnet::createNode(nodeType = "Ridge",
                                    ridge = 1e3)
model <- reservoirnet::link(reservoir, readout)
```

#### Set the data

First we separate the train set on which we will learn the ridge coefficients and the test set on which we will make the forecast. We define the train set to be all the data before 2022-01-01 and the test data to be all the data to have forecast both on train and test sets.

```{r}
# train set
dftrain <- dfOutcome %>% filter(outcomeDate <= traintest_date)
yTrain <- dftrain %>% select(outcome)
yTrain_variation <- dftrain %>% select(outcome_deriv)
xTrain <- dftrain %>% select(hosp, Positive, Tested)
# test set
xTest <- dfOutcome %>% select(hosp, Positive, Tested)
```

We now standardise with the same formula as seen before. We learn the standardisation on the training set and apply it on the test set. Then we convert the dataframe to matrix.

```{r results=FALSE}
# copy train and test sets
xTrainstand <- xTrain
xTeststand <- xTest
# standardise based on training set values
ls_fct_stand <- apply(xTrain,
                      MARGIN = 2,
                      FUN = function(x) function(feature) return(feature/(max(x))))
lapply(X = names(ls_fct_stand),
       FUN = function(x){
         xTrainstand[,x] <<- ls_fct_stand[[x]](feature = xTrain[,x])
         xTeststand[,x] <<- ls_fct_stand[[x]](feature = xTest[,x])
         return()
       })
# convert to array
lsdf <- lapply(list(yTrain = yTrain,
                    yTrain_variation = yTrain_variation,
                    xTrain = xTrainstand,
                    xTest = xTeststand),
               function(x) as.matrix(x))
```

#### Train the model and predict

We then feed the reservoir with the train set. To do so, we set a `warmup` of `30` days during which the data are propagating into the reservoir but not used to fit the output layer.

```{r}
### train the reservoir ridge output
fit <- reservoirnet::reservoirR_fit(node = model,
                                    X = lsdf$xTrain,
                                    Y = lsdf$yTrain,
                                    warmup = 30,
                                    reset = TRUE)
```

Now that the ridge layer is trained, we can forecast. We set the parameter `reset` to `TRUE` in order to clean the reservoir from the data used by the training set.

```{r}
vec_pred <- reservoirnet::predict_seq(node = fit$fit,
                                      X = lsdf$xTest,
                                      reset = TRUE)
```

```{r fig.cap="Forecast"}
dfOutcome %>%
  mutate(pred = vec_pred) %>%
  na.omit() %>%
  ggplot(mapping = aes(x = outcomeDate)) +
  geom_line(mapping = aes(y = outcome,
                          color = "observed")) +
  geom_line(mapping = aes(y = pred,
                          color = "forecast")) +
  geom_vline(mapping = aes(color = "train-test sets",
                           xintercept = traintest_date)) +
  scale_color_manual(values = c("#3772ff", "#080708", "#df2935")) +
  theme_bw() +
  labs(color = "", x = "Date", y = "Hospitalisations")
```

We observe that the model forecast is not fully accurate, both on the test set and the train set. In that case, one option could be to reduce ridge penalisation to fit more closely the data, the optimisation of ridge hyperparameter will be discussed at section [Study case](#studycase). Another possibility is to ease the learning of the algorithm by forecasting the variation of the hospitalisation instead of the number of hospitalised patients. For that step, we will learn on the `outcome_deriv` contained in `yTrain_variation` data which is defined outcome as `outcome_deriv = outcome - hosp`.

```{r fig.cap="Covid-19 hospitalisations forecast. The model is either trained to forecast the number of hospitalisations (denoted Raw) or the variation of the hospitalisations compared to current level of hospitalisation (denoted Variation)"}
## Fit reservoir on outcome variation instead of raw outcome
fit2 <- reservoirnet::reservoirR_fit(node = model,
                                     X = lsdf$xTrain,
                                     Y = lsdf$yTrain_variation,
                                     warmup = 30,
                                     reset = TRUE)
## Get the forecast on the test set
vec_pred2_variation <- reservoirnet::predict_seq(node = fit2$fit,
                                                 X = lsdf$xTest,
                                                 reset = TRUE)
## Transform the outome variation forecast into hospitalisation forecast
vec_pred2 <- vec_pred2_variation + xTest$hosp
## Plot the results
dfOutcome %>%
  mutate(Raw = vec_pred,
         Variation = vec_pred2) %>%
  tidyr::pivot_longer(cols = c(Raw, Variation),
                      names_to = "Outcome_type",
                      values_to = "Forecast") %>%
  na.omit() %>%
  ggplot(mapping = aes(x = outcomeDate)) +
  geom_line(mapping = aes(y = outcome,
                          color = "observed")) +
  geom_line(mapping = aes(y = Forecast,
                          color = "Forecast")) +
  geom_vline(mapping = aes(color = "train-test sets",
                           xintercept = traintest_date)) +
  facet_wrap(Outcome_type ~ .,
             labeller = label_bquote(cols = "Outcome" : .(Outcome_type))) +
  scale_color_manual(values = c("#3772ff", "#080708", "#df2935")) +
  theme_minimal() +
  labs(color = "", x = "Date", y = "Hospitalisations")
```

We observe an improvement of the forecast compared to the forecast of hospitalisation previously discussed. From there, many improvement can be implemented including : frequent update of the model, leverage additional features and hyperparameter optimisation. This notions will be discussed in the [Study case section](#studycase).

## Classification

### The Japanese vowel dataset

This example is largely inspired from the [classification tutorial of reservoirpy](https://github.com/reservoirpy/reservoirpy/blob/master/tutorials/5-Classification-with-RC.ipynb). To illustrate the classification task, we will use the Japanese vowel dataset (@kudo_multidimensional_1999). The data can be loaded from reservoirnet as follow :

```{r}
japanese_vowels <- reservoirnet::generate_data(dataset = "japanese_vowels")[[1]]
X_train <- japanese_vowels$X_train
Y_train <- japanese_vowels$Y_train
X_test <- japanese_vowels$X_test
Y_test <- japanese_vowels$Y_test
```

The dataset comprises 640 vocalizations of the Japanese vowel \ae, contributed by nine distinct speakers. Each vocalization represents a time series spanning between 7 and 29 timesteps, encoded as a 12-dimensional vector denoting the Linear Prediction Coefficients (LPC). A visual representation of six distinct utterances from the test set, originating from three different speakers, is depicted in Figure \@ref(fig:vowelpresentation).

```{r vowelpresentation, fig.cap="Vowel dataset, sample with 3 speakers and 2 utterance each.", echo = FALSE}
vec_sample <- c(1, 2, 41, 42, 71, 72)
dfplot_vowel <- lapply(vec_sample,
                 FUN = function(i){
                   speaker <- which(Y_test[[i]] == 1)
                   X_test[[i]] %>%
                     as.data.frame() %>%
                     tibble::rowid_to_column(var = "Time") %>%
                     tidyr::pivot_longer(cols = -Time,
                                         names_to = "component",
                                         values_to = "LPC") %>%
                     mutate(speaker = speaker, .before = 1,
                            uterrance = i) %>%
                     return()
                 }) %>%
  bind_rows()

ggplot(dfplot_vowel, mapping = aes(x = Time, y = LPC, color = component)) +
  geom_line() +
  facet_wrap(uterrance ~ speaker,
             labeller = label_bquote(cols = "speaker" : .(speaker)),
             ncol = 2) +
  theme_minimal() +
  theme(legend.position = "none")

```

The primary objective involves the attribution of each utterance to its respective speaker, this is denoted as classification or sequence-to-vector encoding. The secondary objective involves the attribution of each time step of each utterance to its speaker, this is denoted as transduction or sequence-to-sequence encoding.

### Classification (sequence-to-vector model)

The first approach is the sequence-to-vector encoding. For this task we aim to predict the speaker of the whole utterance (i.e the label is assigned to the whole sequence). We first start by creating the reservoir and the output layer.

```{r}
reservoir <- reservoirnet::createNode("Reservoir", units = 500,
                                      lr=0.1, sr=0.9,
                                      seed = 1)
readout <- reservoirnet::createNode("Ridge",ridge=1e-6)
```

To perform this task, we need to modify the training and testing process. Leveraging the inherent echo property of the RC, information from preceding time steps is preserved within the reservoir, effectively endowing the RC with a form of memory. Consequently, the final state vector encapsulates insights gathered from all antecedent states. In the context of the sequence-to-vector encoding task, only this ultimate state is employed. This process is executed as follows:

```{r}
states_train = list()
k <- 1
for (x in X_train) {
  states <- reservoirnet::predict_seq(node = reservoir, X = x,
                                      reset=TRUE)
  states_train[[k]] <- t(as.matrix(states[nrow(states),]))
  k <- k+1
}
```

Then we can train the readout based on this last state vector. In that case, `Y_train` contains a single label for each utterance.

```{r}
res <- reservoirnet::reservoirR_fit(readout,X = states_train, Y = Y_train)
```

The prediction is also modified using only the final state :

```{r}
Y_pred <- list()
k <- 1
for (x in X_test) {
  states <- reservoirnet::predict_seq(node = reservoir, X = x,
                                      reset=TRUE)
  y <- reservoirnet::predict_seq(node = readout,
                                 X = as.array(states[nrow(states),]))
  Y_pred[[k]] <- y
  k <- k+1
}
```

Figure \@ref(fig:seqtovec) shows the prediction for the 6 uterrances depicted at figure \@ref(fig:vowelpresentation) where the model correctly identifies the speaker.

```{r seqtovec, fig.cap="Prediction in a sequence-to-sequence approach 6 samples with 3 speakers and 2 utterance each. The speaker to predict is depicted in red. For each of the 6 uterrance, the model correctly identifies the speaker."}
dfplotseqtovec <- lapply(vec_sample,
                 FUN = function(i){
                   speaker <- which(Y_test[[i]][1,] == 1)
                   Y_pred[[i]] %>%
                     as.data.frame() %>%
                     tidyr::pivot_longer(cols = everything(),
                                         names_to = "pred_speaker",
                                         values_to = "prediction") %>%
                     mutate(pred_speaker = gsub(x = pred_speaker,
                                                pattern = "V", "")) %>%
                     mutate(speaker = speaker, .before = 1,
                            uterrance = i,
                            target = speaker == pred_speaker) %>%
                     return()
                 }) %>%
  bind_rows()

ggplot(dfplotseqtovec,
       mapping = aes(x = pred_speaker,
                     y = prediction,
                     fill = target)) +
  geom_bar(stat = "identity") +
  facet_wrap(uterrance ~ speaker,
             labeller = label_bquote(cols = "speaker" : .(speaker)),
             ncol = 2) +
  scale_fill_manual(values = c("darkgrey", "darkred")) +
  theme_minimal() +
  theme(legend.position = "none") +
  labs(y = 'Score',
       x = "Speaker")
```

Then, we can also compute the overall accuracy :

```{r}
accuracy <- function(pred, truth) mean(pred == truth)

Y_pred_class <- sapply(Y_pred,
                       FUN = function(x) apply(as.matrix(x),1,which.max))
Y_test_class <- sapply(Y_test,
                       FUN = function(x) apply(as.matrix(x),1,which.max))

score <- accuracy(pred = Y_test_class, truth = Y_pred_class)

print(paste0("Accuracy: ", round(score * 100,3) ,"%"))
```

### Transduction (sequence-to-sequence model)

For this task, the goal is to predict the speaker for each time step of each utterance. The first step is to get the data where the label is repeated for each time step. This is easily done with the `repeat_targets` argument as follow :

```{r}
japanese_vowels <- reservoirnet::generate_data(
    dataset = "japanese_vowels",
    repeat_targets=TRUE)$japanese_vowels
X_train <- japanese_vowels$X_train
Y_train <- japanese_vowels$Y_train
X_test <- japanese_vowels$X_test
Y_test <- japanese_vowels$Y_test
```

Then we can train a simple Echo State Network to solve this task. For this example we will connect both the input layer and the reservoir layer to the readout layer which is performed by the `%>>%` operator :

```{r}
source <- createNode("Input")
readout <- createNode("Ridge",ridge=1e-6)
reservoir <- createNode("Reservoir",units = 500,lr=0.1, sr=0.9, seed = 1)

model <- list(source %>>% reservoir, source) %>>% readout
```

We can then fit the model and predict the labels for the test data. The `reset` parameter is set to `TRUE` to remove information from the reservoir from the training process.

```{r}
model_fit <- reservoirnet::reservoirR_fit(node = model,
                                          X = X_train,
                                          Y = Y_train,
                                          warmup = 2)

Y_pred <- reservoirnet::predict_seq(node = model_fit$fit,
                                    X = X_test,
                                    reset = TRUE)
```

From the `Y_pred` and `Y_test` we represent at figure \@ref(fig:figseqtoseq) the predictions for the same patients as in figure \@ref(fig:vowelpresentation).

```{r figseqtoseq, fig.cap="Prediction in a sequence-to-sequence approach 6 samples with 3 speakers and 2 utterance each. The higher the score of the speaker, the lighter the color.", fig.height=6}
dfplotseqtoseq <- lapply(vec_sample,
                 FUN = function(i){
                   speaker <- which(Y_test[[i]][1,] == 1)
                   Y_pred[[i]] %>%
                     as.data.frame() %>%
                     tibble::rowid_to_column(var = "Time") %>%
                     tidyr::pivot_longer(cols = -Time,
                                         names_to = "pred_speaker",
                                         values_to = "prediction") %>%
                     mutate(pred_speaker = gsub(x = pred_speaker,
                                                pattern = "V", ""),
                            speaker = speaker,
                            uterrance = i,
                            .before = 1) %>%
                     return()
                 }) %>%
  bind_rows()

ggplot(dfplotseqtoseq, mapping = aes(x = Time,
                                     y = pred_speaker,
                                     fill = prediction)) +
  geom_tile() +
  facet_wrap(uterrance ~ speaker,
             labeller = label_bquote(cols = "speaker" : .(speaker)),
             ncol = 2) +
  theme_minimal() +
  labs(y = 'Predicted speaker',
       fill = "Prediction score")
```

For those 6 utterances, the model correctly identify the speaker for most of the time steps. We can then evaluate the overall accuracy of the model :

```{r}
Y_pred_class <- sapply(Y_pred, FUN = function(x) apply(as.matrix(x),
                                                       1,
                                                       which.max))
Y_test_class <- sapply(Y_test, FUN = function(x) apply(as.matrix(x),
                                                       1,
                                                       which.max))
score <- accuracy(array(unlist(Y_pred_class)), array(unlist(Y_test_class)))

print(paste0("Accuracy: ", round(score * 100,3) ,"%"))
```

# Study case: Covid-19 hospitalisations forecast {#studycase}

## Introduction

Since late 2020, millions of cases of SARS-CoV-2 infection have been documented across the globe [@carrat_evidence_2021, @world_health_organisation_who_2020, @noauthor_estimating_2022]. This ongoing pandemic has exerted significant strain on healthcare systems, resulting in a surge in hospitalizations. This surge, in turn, necessitated modifications to the healthcare infrastructure and gave rise to unprecedented population-wide lockdown measures aimed at preventing the saturation of healthcare facilities [@kim_health_2020, @simoes_organisation_2021, @hubner_surgery_2020]. The capacity to predict the trajectory of the epidemic on a regional scale is of paramount importance for effective healthcare system management.

Numerous COVID-19 forecasting algorithms have been proposed using different methods (e.g ensemble, deep learning, compartmental), yet none has proven entirely satisfactory [@rahimi_review_2021, @cramer_evaluation_2022]. In France, short-term forecasts  with different methods have been evaluated with similar results [@pottier_forecast_2021, @paireau_ensemble_2022, @carvalho_analysis_2021, @mohimont_convolutional_2021]. In this context a machine learning algorithm based on linear regression with elastic-net penalisation, leveraging both EHRs and public data, was implemented at Bordeaux University Hospital [@ferte_benefit_2022]. This model, which aimed at forecasting the number of hospitalised patients at 14 days, showed good performance but struggled to accurately anticipate dynamic shifts of the epidemic.

RC has been used in the context of covid-19 epidemic forecast [@ghosh_reservoir_2021, @kmet_bezier_2019, @liu_nanophotonic_2023, @ray_optimized_2021, @zhang_sentiment_2023]. Among them, @ghosh_reservoir_2021, @liu_nanophotonic_2023 and @ray_optimized_2021 used it to forecast epidemic (@zhang_sentiment_2023 performed sentiment analysis and @kmet_bezier_2019 used it to solve optimal control related to vaccine). The evaluation of RC for epidemic forecast showed promising results in all approaches, being competitive with Long-Short Term Memory (LSTM) and Feed-Forward Neural Network (FFNN) in @ray_optimized_2021. However, the test period was short for @ghosh_reservoir_2021 (21 and 14 days) and @ray_optimized_2021 (86 days) making it difficult to evaluate the behavior of the methods during epidemic dynamic shift. This was not the case for @liu_nanophotonic_2023 (6 months) but they implemented daily ahead forecast which would be difficult to use to manage a hospital. Finally, all three implementations used only one time series as input whereas it has been shown that using different data sources could improve forecast [@ferte_benefit_2022]. Therefore, it is still difficult to assess the usefulness of RC over a large period and using many time series as inputs.

`TODO :` add paragraph about RC in high dimension

`TODO :` add paragraph about hp optimisation for RC (focus on GA)

RC can be approached as a complexification of penalized linear regression where inputs are processed by a reservoir which allows memory and non-linear combinations. As penalised linear regression was the best approach for covid-19 forecast in @ferte_benefit_2022 and that RC showed promising results for epidemic forecast in @ghosh_reservoir_2021, @liu_nanophotonic_2023 and @ray_optimized_2021, we proposed to use RC to forecast hospitalisations at 14 days at the University Hospital of Bordeaux. The main objective of this study is to evaluate the performance of RC for this task. Secondary objective will be (i) to assess the performance of RC depending on the input dimension, (ii) to assess the relevance of Genetic Algorithm (GA) for hyperparameter optimisation and feature selection in this context.

## Methods

### Data

The study utilized aggregated data spanning from May 16, 2020, to January 17, 2022, regarding the COVID-19 epidemic in France, drawing from various sources to enhance forecasting accuracy. These sources encompassed epidemiological statistics from Santé Publique France, weather data from the National Oceanic and Atmospheric Administration (NOAA), both providing department-level data [@etalab_les_2020, @smith_integrated_2011] and Electronic Health Record (EHR) data from the Bordeaux Hospital providing hospital-level data. All data were daily updated. Santé Publique France data included information on hospitalizations, RT-PCR tests, positive RT-PCR results, variant prevalence, and vaccination data, categorized by age groups. NOAA data contributed temperature, wind speed, humidity, and dew point data, allowing for the computation of the COVID-19 Climate Transmissibility Predict Index [@roumagnac_etude_2021]. EHRs data included hospitalizations, ICU admissions, ambulance service records, and emergency unit notes, with relevant COVID-19-related concepts extracted from the notes. Data are discussed more in depth in @ferte_benefit_2022.

First and second derivative over the last $7$ days were computed to enrich model information. To take into account measurement error and daily noise variation, data were smoothed using a local polynomial regression with a span of 21 days.

### Evaluation framework

The task was to forecast 14 days ahead the number of hospitalised patients. As seen at section [Regression](#basicregression), we will train the model to predict the variation of hospitalisation defined as $outcome_{t+14} = hosp_{t+14} - hosp_{t}$. Metrics computation and visualisations will be performed on the predicted number of hospitalizations denoted as $\hat{y_{t+14}} = \widehat{outcome_{t+14}} + hospitalizations_{t}$ and the observed number of hospitalisations at time $t+14$ denoted as $y_{t+14} = hospitalizations_{t+14}$

The dataset was separated into two periods. First period from May 16, 2020 to March 1, 2021 served to identify relevant hyperparameters. Remaining data was used to evaluate the model performance. As the time serie is not stationary and most appropriate hyperparameter value might change over time, we also investigated the effect of hyperparameter update every month.

The performance of the model was evaluated according to several metrics: the median absolute error ($MAE = median(|\hat{y_t}-y_t|)$) , the median relative error ($MRE = median(|\frac{\hat{y_t}-y_t}{y_t}|)$), the median absolute error to baseline ($MAEB =  median(|\hat{y_t}-y_t| - |y_{t-14} - y_t|)$), the median relative error to baseline ($MREB = median(\frac{|\hat{y_t}-y_t|}{|y_{t-14} - y_t|})$). Such that the model denoted as baseline was the model defined as $\hat{y_t} = y_{t-14}$. All those metrics reflects different information. $MAE$ and $MAEB$ are highly sensitive to forecast error when the number of hospitalizations is high. $MAEB$ encapsulates information about the current dynamic of the hospitalizations : for the same absolute error, absolute error to baseline will be lower if the number of hospitalization is not constant. **MAEB = redundant with MAE ?**. $MRE$ is highly sensitive to forecast error when the number of hospitalizations is low because the denominator will be small. $MREB$ is highly sensitive to small forecast error when the number of hospitalized patients is constant over time. For each metric, the median was chosen over the mean to be robust to outliers. For instance, for relative error, when the outcome is low (e.g equal to 1 hospitalization), an error of 5 hospitalizations could results to a 400% relative error. **But that might favor models with chaotic metric because only half of them will be used to compute the error ? => keep median for relative error and mean of absolute error and optimize on MAE instead of MREB ? Also, because MAE is a difference it is similar if we compute it on the number of hospitalization or on the variation of the number of hospitalization. Also we might discuss to penalize more the error when the number of hospitalizations is high (already done implicitly by AE) and when there is a dynamic shift => ponderate AE by absolute value of second derivative ?**.

### Hyperparameter optimisation using GA

RC relies mainly on 4 hyperparameters including the leaking rate (i.e "memory" parameter), spectral radius (i.e "chaoticity" parameter), input scaling (i.e "feature gain" parameter) and ridge (i.e penalization parameter). Input scaling can be either common to all features or specific to each feature which increases the number of hyperparameter by the number of features. As the relevancy of feature for forecast evolves over time, we explored (i) filter based feature selection based on elastic-net before RC which has a penalization hyperparameter denoted as $enet$ and (ii) wrapper feature selection for which each feature has an additional binary hyperparameter defining if it should be selected or not.

Regarding the number of hyperparameter, an automatic approach is necessary the relevant hyperparameters. We chose to use a genetic algorithm (GA) which has the benefit of making few assumptions on the link function between the vector of hyperparameter value and the objective function but might need many trials which are possible due to the fast of RC. The objective function of GA was to minimize the $MREB$ metric **(change ?)**. The pseudo-code of GA is defined as follow :

1.  Initialize :

-   Population parameters : $N_{pop} = 200$, $N_e = 100$,
    $N_{generation} = 30$
-   Cross-over parameters : $N_{tournament} = 2$
-   Mutation parameters : $p_{mutQuant} = .5$, $p_{mutCat} = .25$,
    $\sigma = 1$ ($\sigma = 0.1$ for leaking rate as the hyperparameter
    range is shorter)
-   Define the $hyperparameter\_list$, a list containing each
    hyperparameter denoted as $param$.
-   `for` each $param$ in $hyperparameter\_list$ define hyperparameter
    $search\_space$ :
    -   the $lower$ and $upper$ bounds,
    -   the $type$ (numeric, integer, categorical)
    -   if it should be $log$ transformed (True, False)

2.  Define main functions
    -   Define $tournamentSelection(N_{pop}, N_{tournament})$:
        -   Get the best $N_{pop}$ individuals from previous generations
        -   Randomly select $N_{tournament}$ challengers among them
        -   Get the best individuals from the challengers
        -   Repeat twice to get a father and a mother
        -   `return` $father, \: mother$
    -   Define
        $crossoverMutation(pere\$param\$value, mere\$param\$value, param\$search\_space)$:
        -   `if` $search\_space\$log$ $\newline$
            $\text{} \qquad pere\$param\$value = log_{10}(pere\$param\$value)$
            $\newline$
            $\text{} \qquad mere\$param\$value = log_{10}(mere\$param\$value)$

        -   sample $alp$ and $mut$ probabilities from $\mathcal{U}(0,1)$

        -   Cross-over, and define $child\$param\$value$ as :

            -   Numerical :
                $alp*pere\$param\$value + (1-alp)*mere\$param\$value$
            -   Integer :
                $round( alp*pere\$param\$value + (1-alp)*mere\$param\$value)$
            -   Categorical :
                $sample(x = c(pere\$param\$value, mere\$param\$value), \newline\text{}\qquad\text{}\qquad\text{}\qquad\text{}\qquad\text{}\qquad prob = c(alp, 1-alp))$

        -   `if` $mut < p_{mutQuant}$ or $mut < p_{mutCat}$ for
            quantitative and categorical features respectively, mutate :

            -   Categorical : sample another modality
            -   Integer : add or substract 1 at random
            -   Numerical : Add $\sigma", "imes \mathcal{N}(0,1)$

        -   `if` $search\_space\$log$ :
            $child\$param\$value = 10^{child\$param\$value}$

        -   `return` $child\$param\$value$
    -   Define $geneticSearch(N_{pop}, N_{tournament})$ :
        -   $pere, \: mere = tournamentSelection(N_{pop}, N_{tournament})$
        -   `for` $param$ in $hyperparameter\_list$ : $\newline$
            $\text{} \qquad child\$param\$value = crossoverMutation(\newline\text{}\qquad\text{}\qquad\text{}\qquad\text{}\qquad\text{}\qquad pere\$param\$value, \newline\text{}\qquad\text{}\qquad\text{}\qquad\text{}\qquad\text{}\qquad mere\$param\$value, \newline\text{}\qquad\text{}\qquad\text{}\qquad\text{}\qquad\text{}\qquad param\$search\_space)$
        -   `return` $child$
3.  Run the algorithm
    -   Step 1 : Initialize genetic algorithm
        -   Sample $N_{pop}$ individuals (i.e set of hyperparameters)
            using random search
    -   Step 2 : Run genetic algorithm
        -   $generation = 1$
        -   `while` $generation < Ngeneration$ :
            -   $generation = generation + 1$
            -   sample $N_{pop}$ individuals using $geneticSearch$
                function

### Feature selection with RC

We investigated the performance of RC using various feature selection approach and input scaling configuration. The following setting were evaluated :

- Feature selection based on expert inputs with common input scaling
- Feature selection based on expert inputs with specific input scaling for each feature
- Genetic algorithm feature selection with common input scaling
- Genetic algorithm feature selection with specific input scaling for each feature
- Elastic-net feature selection with common input scaling

Experts inputs were a priori defined features that were judge important for epidemic forecast : hospitalizations, positive RT-PCR, positive RT-PCR among the 60

In addition, we investigated if monthly update of hyperparameter was improving the performance and if optimizing the random seed (which defines the connections inside the reservoir) was improving the results.

## Results

### Data

```{r casestudyhospitalisations, echo = FALSE, fig.cap = "Hospitalisations at the university hospital of Bordeaux", out.width="75%"}
knitr::include_graphics(path = here::here("draft_jss/images/monthly update/fig-eval-setting-1.png"))
```

### Present results from GA

### Present forecast performance

```{r echo = FALSE}
tibble::tribble(
  ~"Update", ~"Feature", ~"Nb. Features", ~"MAE", ~"MRE", ~"MAEB", ~"MREB ",
  "No", "Epi - Single IS", 14.0, 13.79, 0.34, -2.92, 0.77 ,
  "Yes", "Epi - Single IS", 14.0, 10.16, 0.32, -5.09, 0.67 ,
  "No", "Epi - Multiple IS", 14.0, 9.35, 0.28, -5.31, 0.66 ,
  "Yes", "Epi - Multiple IS", 14.0, 11.83, 0.31, -2.03, 0.80 ,
  "No", "GA - Single IS", 231.0, 10.62, 0.28, -5.05, 0.72 ,
  "Yes", "GA - Single IS", 225.0, 9.33, 0.28, -4.76, 0.72 ,
  "No", "GA - Multiple IS", 227.0, 9.67, 0.33, -3.64, 0.71 ,
  "Yes", "GA - Multiple IS", 227.5, 9.45, 0.29, -3.90, 0.69 ,
  "No", "GA - Multiple IS (seed)", 225.0, 10.68, 0.27, -4.37, 0.72 ,
  "Yes", "GA - Multiple IS (seed)", 227.5, 10.20, 0.28, -5.33, 0.68 ,
  "No", "Enet - Single IS", 172.0, 11.72, 0.31, -3.29, 0.79 ,
  "Yes", "Enet - Single IS", 208.0, 13.68, 0.35, -2.58, 0.81) %>%
  knitr::kable(caption = "Model performance with or without monthly update (Update), feature selection (Feature). For each setting, 40 reservoir are computed and the forecast is the median of the 40 forecast. Results show the mean number of features and the performance metrics. MAE = Median Absolute Error, MRE = Median Relative Error, MAEB = Median Absolute Error to Baseline, MREB = Median Relative Error to Baseline.",
               booktabs = TRUE)
```

```{r echo = FALSE, fig.cap = "Reservoir computing forecast depending on the setting without monthly update. Red line is the median forecast of 40 reservoirs. Grey lines are individual forecast of each of the 40 reservoir.", out.width="75%"}
knitr::include_graphics(path = here::here("draft_jss/images/monthly update/fig-eval-prediction-noupdate-1.png"))
```

```{r echo = FALSE, fig.cap = "Reservoir computing forecast depending on the setting with monthly update. Red line is the median forecast of 40 reservoirs. Grey lines are individual forecast of each of the 40 reservoir.", out.width="75%"}
knitr::include_graphics(path = here::here("draft_jss/images/monthly update/fig-eval-prediction-update-1.png"))
```

## Discussion

# Previous work

Those work were done previously, the setting of train/test and
hyperparameter optimisation were different and probably they should be
done again in a similar setting for relevant comparison.

## Raw outcome, first derivative or second derivative ?

See
<https://github.com/thomasferte/PredictCovid/blob/esn_update_report/reporting/02_esn/01_explore_esn_prediction/00_reporting/explore_esn.md>

## Raw feature or scaled feature ?

See
<https://github.com/thomasferte/PredictCovid/blob/esn_update_report/reporting/02_esn/01_explore_esn_prediction/00_reporting/explore_esn.md>

## Smoothed or not smoothed

See
<https://github.com/thomasferte/PredictCovid/blob/esn_update_report/reporting/02_esn/01_explore_esn_prediction/00_reporting/explore_esn.md>

## Number of nodes

See
<https://github.com/thomasferte/PredictCovid/blob/esn_update_report/reporting/02_esn/01_explore_esn_prediction/00_reporting/explore_esn_r_pipeline.md>

## Use of second derivative among the interesting features

See
<https://github.com/thomasferte/PredictCovid/blob/esn_update_report/reporting/02_esn/01_explore_esn_prediction/00_reporting/tune_esn2.md>

## Results of random sampling with R

See
<https://github.com/thomasferte/PredictCovid/blob/esn_update_report/reporting/02_esn/01_explore_esn_prediction/meeting_1801/master_report.md>

# Discussion and conclusion

# Bibliography
